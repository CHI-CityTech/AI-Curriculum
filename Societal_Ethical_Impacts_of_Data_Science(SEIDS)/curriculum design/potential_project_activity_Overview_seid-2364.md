# **Project Activity Overview – SEID 2364**  
### *Societal and Ethical Impacts of Data Science*  

Projects in *Societal and Ethical Impacts of Data Science* are designed as multimodal explorations of real-world ethical challenges within data-driven systems. Each student will engage across **three collaborative configurations** over the semester:  
1. **Individual Human Projects** – reflective inquiries or micro-case analyses focused on personal ethical reasoning and communication modality.  
2. **Human-Human Team Projects** – small interdisciplinary groups examining shared ethical problems through collective debate, negotiation, and synthesis.  
3. **Human-AI Collaborative Projects** – teams (or individuals) working alongside an assigned or self-trained AI associate to co-develop, document, and critique ethical reasoning, treating the AI as a cognitive partner rather than a passive tool.  

Students will select their ethical challenge from a **domain matrix**—for example: healthcare data, algorithmic governance, surveillance systems, autonomous mobility, financial technologies, educational analytics, or creative generative AI. Each domain represents a distinct ethical tension between innovation and consequence. Within those contexts, students investigate *who or what holds agency*, *how mediation shapes accountability*, and *how ethical responsibility is distributed*.

---

## **Deliverables**
Each project generates outputs in **multiple modalities**, demonstrating ethical literacy through both **content** and **form**:
- **Written Analysis (Textual)** – a concise ethical case study or research brief articulating the dilemma, stakeholders, and argumentation framework.  
- **Visual or Spatial Representation (Diagrammatic)** – a BBS map or flowchart showing the mediation of intelligence, information, and consequence across spaces.  
- **Oral / Performance Component (Communicative)** – a presentation, recorded dialogue, or interactive session (possibly with AI participation) illustrating the reasoning process.  
- **Reflective Component (Metacognitive)** – a short journal or AI log analyzing the communication and collaboration itself as an ethical act.  

These deliverables form a **portfolio of ethical practice**, showing progression from individual reflection to social collaboration to hybrid human–machine inquiry.  The final synthesis integrates all three perspectives, allowing students to demonstrate how ethical awareness transforms across modalities, intelligences, and disciplinary domains.

---

## **Guidelines for Ethical AI Use in Human Teams**
Human/Human teams may employ AI tools and systems without those systems being considered formal team members.  AI may function as a **resource**, **stimulus**, or **instrument**, provided authorship and accountability remain fully human.  

**Permitted and Ethical AI Roles:**
1. **AI as Analytical Instrument** – used for background research or summarization; humans verify and interpret results.  
2. **AI as Stimulus for Debate** – generates counterpoints or alternative framings; humans analyze critically.  
3. **AI as Documentation Assistant** – manages meeting notes or summaries without shaping decisions.  
4. **AI as Scenario Simulator** – produces hypothetical cases for human analysis.  
5. **AI as Style Mediator** – supports clarity or translation, not argumentation.  

Each team must document how AI was employed, verify accuracy independently, and reflect on how its use affected human reasoning.  In BBS terms, AI in this configuration acts as a **Vector**, mediating communication but not serving as a Source or Destination intelligence.

---

## **Evolving Team Structures and AI Agency**
Building on traditional collaboration models, SEID 2364 introduces **AI agents as designed team members**, encouraging students to explore the ethics of co-creation, distributed intelligence, and moral negotiation.  

### **AI as Designed Teammate**
Students may design, prompt-train, or fine-tune an **AI teammate** to participate in group reasoning.  Each agent is given a defined role and ethical orientation (e.g., skeptic, compliance officer, cultural interpreter, creative ethicist).  The team documents its creation process, dialogue traces, and emergent behavior through an **AI Teammate Dossier**, reflecting on what the interaction reveals about machine and human moral reasoning.

### **Integration into CHI Collaborative Structures**
Student teams may extend their projects beyond the classroom by linking into **CHI collaborative infrastructures** (e.g., GitHub repositories, BBS modeling protocols, AI documentation standards).  Teams adopting this model can interact asynchronously with other CHI or City Tech projects, sharing reflections and insights through ethical review exchanges or cross-repository commentary.  

This creates a living research ecosystem in which student work contributes to ongoing CHI initiatives—embedding ethical awareness into the broader ecosystem of Blended Reality, BBS, and Collaborative AI.

### **Future Collaborative Extensions**
The SEID 2364 project model is designed to scale.  Future iterations may involve cross-institutional partnerships with other ethics or data-science programs, enabling international dialogue, shared AI agents trained on diverse ethical frameworks, or guest participation from research collaborators.  These expansions will deepen the course’s mission: to model how ethics, intelligence, and communication interconnect across human and artificial boundaries.

---

**Summary:**  
Through individual, team, and hybrid collaborations, SEID 2364 positions students as both practitioners and analysts of mediated ethics. Whether working with humans, AI systems, or distributed networks of intelligences, students engage in a continual process of reflection, accountability, and transformation—embodying the central BBS principle that ethical understanding arises through communication within space and time.

